{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b9840f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "DETECTRON2 for stain detection\n",
    "\n",
    "Build cuda_11.5.r11.5/compiler.30672275_0\n",
    "torch:  1.11 ; cuda:  cu115\n",
    "detectron2: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672164f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1, LossEvalHook(\n",
    "            cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc62cd",
   "metadata": {},
   "source": [
    "Configuration for MASK-RCNN\n",
    "\n",
    "Object detection and instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml\"\n",
    "checkpoint_url = \"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml\"\n",
    "\n",
    "output_dir = \"./output/instance_segmentation\"\n",
    "\n",
    "num_classes = 1\n",
    "device = \"cuda\"\n",
    "\n",
    "train_dataset_name = \"Stain_train\"\n",
    "train_images_path = \"train2\"\n",
    "train_json_annot_path = \"train2.json\"\n",
    "\n",
    "val_dataset_name = \"Stain_val\"\n",
    "val_images_path = \"val2\"\n",
    "val_json_annot_path = \"val2.json\"\n",
    "\n",
    "conf_save_path = \"IS_cfg.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53043f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(name=train_dataset_name, metadata={}, json_file=train_json_annot_path, image_root=train_images_path)\n",
    "register_coco_instances(name=val_dataset_name, metadata={}, json_file=val_json_annot_path, image_root=val_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834efe46",
   "metadata": {},
   "source": [
    "Check data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(dataset_name, n=1):\n",
    "    dataset_custom = DatasetCatalog.get(dataset_name)\n",
    "    dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
    "    \n",
    "    for s in random.sample(dataset_custom, n):\n",
    "        img = cv2.imread(s[\"file_name\"])\n",
    "        v = Visualizer(img[:, :, ::-1], metadata=dataset_custom_metadata, scale=0.3)\n",
    "        out = v.draw_dataset_dict(s)\n",
    "        plt.figure(figsize=(15,20))\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70923b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(train_dataset_name, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bc218",
   "metadata": {},
   "source": [
    "Train Mask-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_cfg(config_file_path, checkpoint_url, train_dataset_name, val_dataset_name, num_classes, device, output_dir):\n",
    "    \n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_file_path))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(checkpoint_url)\n",
    "    cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
    "    cfg.DATASETS.TEST = (val_dataset_name, )\n",
    "    cfg.TEST.EVAL_PERIOD = 20\n",
    "    \n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2      # use 6 for segementation and 2 for object detection \n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    cfg.SOLVER.MAX_ITER = 3000\n",
    "    cfg.SOLVER.STEPS = [] \n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "    cfg.MODEL.DEVICE = device\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "import logging\n",
    "\n",
    "cfg = get_train_cfg(config_file_path, checkpoint_url, train_dataset_name, val_dataset_name, num_classes, device, output_dir)\n",
    "\n",
    "with open(conf_save_path, 'wb') as f:\n",
    "    pickle.dump(cfg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg)\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78e753",
   "metadata": {},
   "source": [
    "Evaluate on Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf_save_path, 'rb') as f:\n",
    "    cfg = pickle.load(f)\n",
    "    \n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"Stain_val\", output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, \"Stain_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2cf36",
   "metadata": {},
   "source": [
    "Evaluate on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_image(image_path, predictor):\n",
    "    img = cv2.imread(image_path)\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata={}, scale=0.3, instance_mode=ColorMode.IMAGE_BW )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba47dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test2\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for f in dir_list: \n",
    "    \n",
    "    image_path = \"test2/\" + f\n",
    "    print(image_path)\n",
    "    on_image(image_path, predictor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e1eb9",
   "metadata": {},
   "source": [
    "Change configuration for RCNN\n",
    "\n",
    "Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\"\n",
    "checkpoint_url = \"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\"\n",
    "\n",
    "\n",
    "output_dir = \"./output/object_detection\"\n",
    "\n",
    "conf_save_path = \"OD_cfg.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecddbe0",
   "metadata": {},
   "source": [
    "Train RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_train_cfg(config_file_path, checkpoint_url, train_dataset_name, val_dataset_name, num_classes, device, output_dir)\n",
    "\n",
    "with open(conf_save_path, 'wb') as f:\n",
    "    pickle.dump(cfg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77605253",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Evaluate on Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec621926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "with open(conf_save_path, 'rb') as f:\n",
    "    cfg = pickle.load(f)\n",
    "    \n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "evaluator = COCOEvaluator(\"Stain_val\", output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, \"Stain_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5f7b1",
   "metadata": {},
   "source": [
    "Evaluate on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0277128",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test2\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for f in dir_list: \n",
    "    \n",
    "    image_path = \"test2/\" + f\n",
    "    print(image_path)\n",
    "    on_image(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1f9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b538f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
